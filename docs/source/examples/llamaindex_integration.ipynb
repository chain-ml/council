{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LlamaIndex integration\n",
    "\n",
    "In this notebook, we show how it's easy to build **ChainML** agents that leverage the power of **LlamaIndex** to integrate data for your agents.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Integration with **LlamaIndex** is easy and straightforward.\n",
    "To use **LlamaIndex** with the **ChainML** framework, you will need to install \"Llama-Index\" via pip.\n",
    "\n",
    "### Example\n",
    "\n",
    "```sh\n",
    "$ pip install Llama-Index\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Example of using Llama Index to retrieve relevant information from documents - here we use the book, the Great Gatbsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download Great Gatsby example from Llama Index\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "url = \"https://github.com/jerryjliu/llama_index/blob/main/examples/gatsby/gatsby_full.txt\"\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "os.makedirs(\"gatsby_download\", exist_ok=True)\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(os.path.join(\"gatsby_download\", filename), \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# build index of book\n",
    "documents = SimpleDirectoryReader(\"gatsby_download\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gatsby and Daisy meet at Gatsby's mansion, which is located in East Egg.\n"
     ]
    }
   ],
   "source": [
    "# check the index is working\n",
    "response = query_engine.query(\"Where do Gatsby and Daisy meet?\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Examples\n",
    "### Chain Using LlamaIndex\n",
    "\n",
    "Let's create a chain that uses LlamaIndex to retrieve relevant context for a user's query for a simple chatbot that can query the data. We will look up context then feed it into a prompt template for an LLMSkill to respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainml_engine.core import SkillBase, Budget\n",
    "from chainml_engine.core.execution_context import SkillContext, SkillMessage\n",
    "\n",
    "from llama_index.indices.query.base import BaseQueryEngine\n",
    "\n",
    "\n",
    "class LlamaIndexSkill(SkillBase):\n",
    "    queryEngine: BaseQueryEngine\n",
    "\n",
    "    def __init__(self, queryEngine: BaseQueryEngine):\n",
    "        SkillBase.__init__(self, \"llama index skill\")\n",
    "        self.queryEngine = queryEngine\n",
    "\n",
    "    def execute(self, context: SkillContext, budget: Budget) -> SkillMessage:\n",
    "        prompt = context.chatHistory.last_user_message().unwrap(\"no user message\").message\n",
    "        print(prompt)\n",
    "        response = self.queryEngine.query(prompt)\n",
    "        return self.build_success_message(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap into a trivial agent that just answers document queries\n",
    "from chainml_engine.skill import LLMSkill\n",
    "from chainml_engine.core import Chain, Agent\n",
    "from chainml_engine.controller.basic_controller import BasicController\n",
    "from chainml_engine.evaluator.basic_evaluator import BasicEvaluator\n",
    "\n",
    "index_skill = LlamaIndexSkill(query_engine)\n",
    "chain = Chain(\"docindex\", \"document index\", [index_skill])\n",
    "agent = Agent(BasicController(), [chain], BasicEvaluator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who falls in love with Daisy?\n",
      "\n",
      "Gatsby falls in love with Daisy.\n"
     ]
    }
   ],
   "source": [
    "from chainml_engine.llm.llm_message import LLMMessage\n",
    "from chainml_engine.core.execution_context import AgentContext, ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "# chat_history.add_user_message(message=\"Whose eyes are on the billboard?\")\n",
    "# chat_history.add_user_message(\"What are the personalities of Tom and Daisy?\")\n",
    "# chat_history.add_user_message(\"What era does the book take place in?\")\n",
    "chat_history.add_user_message(\"Who falls in love with Daisy?\")\n",
    "context = AgentContext(chat_history=chat_history)\n",
    "result = agent.execute(context=context, budget=Budget(20))\n",
    "print(result.messages[-1].message.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent to use index to provide context for more complex answers\n",
    "from chainml_engine.llm import OpenAILLM, OpenAIConfiguration\n",
    "import dotenv\n",
    "from chainml_engine.prompt import PromptBuilder\n",
    "from chainml_engine.prompt.prompt_builder import PromptToMessages\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "config = OpenAIConfiguration.from_env()\n",
    "config.model = \"gpt-3.5-turbo\"\n",
    "llm = OpenAILLM(config)\n",
    "\n",
    "context_prompt = PromptToMessages(\n",
    "    PromptBuilder(\"Please identify query terms to respond to the following user request {{chat_history.last_message}}\")\n",
    ")\n",
    "context_query_skill = LLMSkill(\n",
    "    llm,\n",
    "    \"You are an expert in the Great Gatbsy. Identify relevant query terms to search for context in the book.\",\n",
    "    context_messages=context_prompt.get_messages_from_prompt,\n",
    ")\n",
    "\n",
    "index_skill = LlamaIndexSkill(query_engine)\n",
    "index_prompt = PromptToMessages(\n",
    "    PromptBuilder(\n",
    "        \"Here are relevant quotes from the book: {{chain_history.last_message}} \\nUse this to respond to the following user request {{chat_history.last_message}}\"\n",
    "    )\n",
    ")\n",
    "response_skill = LLMSkill(\n",
    "    llm,\n",
    "    \"You are an expert in the Great Gatbsy. Provide a helpful response to the user's question\",\n",
    "    context_messages=index_prompt.get_messages_from_prompt,\n",
    ")\n",
    "\n",
    "chain = Chain(\"docindex\", \"document index\", [context_query_skill, index_skill, response_skill])\n",
    "agent = Agent(BasicController(), [chain], BasicEvaluator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s %(levelname)s %(threadName)s %(name)s:%(funcName)s:%(lineno)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S%z\",\n",
    ")\n",
    "## uncomment me to see the engine logs\n",
    "logging.getLogger(\"chainml_engine\").setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the key plot events in the book?\n",
      "In \"The Great Gatsby,\" there are several key plot events that drive the narrative:\n",
      "\n",
      "1. The heated argument and confrontation between the narrator and Tom Buchanan at the party in New York City.\n",
      "2. Myrtle Wilson recounting the story of her first meeting with Tom, hinting at their affair.\n",
      "3. Tom Buchanan breaking Myrtle's nose during a passionate argument.\n",
      "4. The small dog sitting on the table during the party, representing the reckless and careless behavior of the characters.\n",
      "5. The narrator wiping the spot of dried lather from Mr. McKee's cheek, symbolizing his tendency to get involved in others' affairs.\n",
      "6. A heated argument between Tom Buchanan and Myrtle Wilson over Daisy's name, revealing tensions and resentment.\n",
      "7. Jordan Baker emerging from the house and standing at the head of the marble steps, capturing the attention of the narrator.\n",
      "8. The narrator and Jordan Baker connecting and exploring the garden together.\n",
      "9. Conversations between two unidentified girls in yellow dresses discussing rumors about Gatsby, suggesting he may have killed a man and been a German spy during the war.\n",
      "\n",
      "These events are crucial in driving the story forward and shedding light on the complexities and hidden desires of the characters in \"The Great Gatsby.\"\n"
     ]
    }
   ],
   "source": [
    "chat_history = ChatHistory()\n",
    "# chat_history.add_user_message(message=\"Whose eyes are on the billboard?\")\n",
    "# chat_history.add_user_message(\"What are the personalities of Tom and Daisy?\")\n",
    "# chat_history.add_user_message(\"What era does the book take place in?\")\n",
    "chat_history.add_user_message(\"What are the key plot events in the book?\")\n",
    "# chat_history.add_user_message(\"What is the significance of the eyes on the billboard?\")\n",
    "context = AgentContext(chat_history=chat_history)\n",
    "result = agent.execute(context=context, budget=Budget(20))\n",
    "print(result.messages[-1].message.message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
