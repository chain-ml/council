{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LlamaIndex integration\n",
    "\n",
    "In this notebook, we show how it's easy to build **ChainML** agents that leverage the power of **LlamaIndex** to integrate data for your agents.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Integration with **LlamaIndex** is easy and straightforward.\n",
    "To use **LlamaIndex** with the **ChainML** framework, you will need to install \"Llama-Index\" via pip.\n",
    "\n",
    "### Example\n",
    "\n",
    "```sh\n",
    "$ pip install Llama-Index\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-07-22T20:26:47.309884Z",
     "start_time": "2023-07-22T20:26:47.301155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "print(os.getenv(\"OPENAI_API_KEY\", None) is not None )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Example of using Llama Index to retrieve relevant information from documents - here we use the book, the Great Gatbsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download Great Gatsby example from Llama Index\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "url = \"https://github.com/jerryjliu/llama_index/blob/main/examples/gatsby/gatsby_full.txt\"\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "os.makedirs(\"gatsby_download\", exist_ok=True)\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(os.path.join(\"gatsby_download\", filename), \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# build index of book / This step could be slow\n",
    "documents = SimpleDirectoryReader(\"gatsby_download\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T20:26:55.775323Z",
     "start_time": "2023-07-22T20:26:55.770335Z"
    }
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T20:26:59.342611Z",
     "start_time": "2023-07-22T20:26:57.517532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gatsby and Daisy meet at Gatsby's house on Long Island.\n"
     ]
    }
   ],
   "source": [
    "# check the index is working\n",
    "response = query_engine.query(\"Where do Gatsby and Daisy meet?\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Examples\n",
    "### Chain Using LlamaIndex\n",
    "\n",
    "Let's create a chain that uses LlamaIndex to retrieve relevant context for a user's query for a simple chatbot that can query the data. We will look up context then feed it into a prompt template for an LLMSkill to respond.\n",
    "\n",
    "We define a LlamaIndexSkill that uses a query engine to look up indexed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T20:27:01.745435Z",
     "start_time": "2023-07-22T20:27:01.743520Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from council.runners import Budget\n",
    "from council.contexts import SkillContext, ChatMessage\n",
    "from council.skills import SkillBase\n",
    "from llama_index.indices.query.base import BaseQueryEngine\n",
    "\n",
    "\n",
    "class LlamaIndexSkill(SkillBase):\n",
    "    queryEngine: BaseQueryEngine\n",
    "\n",
    "    def __init__(self, query_engine: BaseQueryEngine):\n",
    "        SkillBase.__init__(self, \"llama index skill\")\n",
    "        self.queryEngine = query_engine\n",
    "\n",
    "    def execute(self, context: SkillContext, budget: Budget) -> ChatMessage:\n",
    "        prompt = context.chat_history.try_last_user_message.unwrap(\"no user message\").message\n",
    "        print(prompt)\n",
    "        response = self.queryEngine.query(prompt)\n",
    "        return self.build_success_message(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T20:27:03.883477Z",
     "start_time": "2023-07-22T20:27:03.870284Z"
    }
   },
   "outputs": [],
   "source": [
    "from council.agents import Agent\n",
    "from council.chains import Chain\n",
    "\n",
    "# wrap into a trivial agent that just answers document queries\n",
    "index_skill = LlamaIndexSkill(query_engine)\n",
    "agent = Agent.from_skill(index_skill, \"document index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T20:27:06.557927Z",
     "start_time": "2023-07-22T20:27:05.167487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who falls in love with Daisy?\n",
      "\n",
      "Gatsby falls in love with Daisy.\n"
     ]
    }
   ],
   "source": [
    "# message=\"Whose eyes are on the billboard?\"\n",
    "# message=\"What are the personalities of Tom and Daisy?\"\n",
    "# message=\"What era does the book take place in?\"\n",
    "message=\"Who falls in love with Daisy?\"\n",
    "\n",
    "result = agent.execute_from_user_message(message)\n",
    "print(result.best_message.message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of integrating LlamaIndex into a more capable chain - this chain answers a user request for information about the book by:\n",
    "1. formulating a query for information to retrieve from the book using an LLM (here GPT-3.5-Turbo)\n",
    "2. passing that query to LlamaIndex to retrieve relevant passages from the book  \n",
    "3. passing those passages as context to the LLM along with the original query to generate a summary response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T20:27:08.947673Z",
     "start_time": "2023-07-22T20:27:08.937058Z"
    }
   },
   "outputs": [],
   "source": [
    "from council.utils import Option\n",
    "from council.evaluators import BasicEvaluator\n",
    "from council.controllers import BasicController\n",
    "from council.prompt import PromptBuilder\n",
    "from council.skills import PromptToMessages, LLMSkill\n",
    "from council.llm import OpenAILLMConfiguration, OpenAILLM\n",
    "\n",
    "# agent to use index to provide context for more complex answers\n",
    "import dotenv\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "config = OpenAILLMConfiguration.from_env()\n",
    "config.model = Option(\"gpt-3.5-turbo\")\n",
    "llm = OpenAILLM(config)\n",
    "\n",
    "context_prompt = PromptToMessages(\n",
    "    PromptBuilder(\"Please identify query terms to respond to the following user request {{chat_history.last_message}}\")\n",
    ")\n",
    "context_query_skill = LLMSkill(\n",
    "    llm,\n",
    "    \"You are an expert in the Great Gatbsy. Identify relevant query terms to search for context in the book.\",\n",
    "    context_messages=context_prompt.to_user_message,\n",
    ")\n",
    "\n",
    "index_skill = LlamaIndexSkill(query_engine)\n",
    "index_prompt = PromptToMessages(\n",
    "    PromptBuilder(\n",
    "        \"Here are relevant quotes from the book: {{chain_history.last_message}} \\nUse this to respond to the following user request {{chat_history.last_message}}\"\n",
    "    )\n",
    ")\n",
    "response_skill = LLMSkill(\n",
    "    llm,\n",
    "    \"You are an expert in the Great Gatbsy. Provide a helpful response to the user's question\",\n",
    "    context_messages=index_prompt.to_user_message,\n",
    ")\n",
    "\n",
    "chain = Chain(\"docindex\", \"document index\", [context_query_skill, index_skill, response_skill])\n",
    "agent = Agent(BasicController(), [chain], BasicEvaluator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T20:27:13.068029Z",
     "start_time": "2023-07-22T20:27:13.064097Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s %(levelname)s %(threadName)s %(name)s:%(funcName)s:%(lineno)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S%z\",\n",
    ")\n",
    "## uncomment me to see the engine logs\n",
    "logging.getLogger(\"council\").setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T20:27:24.594760Z",
     "start_time": "2023-07-22T20:27:17.387445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the key plot events in the book?\n",
      "The key plot events in the book \"The Great Gatsby\" include Gatsby's funeral, the man with owl-eyed glasses attending the funeral, Tom and Jordan taking Nick away from the funeral, Nick's realization that it is his 30th birthday, the discovery of George Wilson's wife locked in the garage, and the death car accident.\n"
     ]
    }
   ],
   "source": [
    "# message=\"Whose eyes are on the billboard?\")\n",
    "# message=\"What are the personalities of Tom and Daisy?\"\n",
    "# message=\"What era does the book take place in?\"\n",
    "# message=\"What is the significance of the eyes on the billboard?\"\n",
    "message=\"What are the key plot events in the book?\"\n",
    "\n",
    "result = agent.execute_from_user_message(message=message)\n",
    "print(result.best_message.message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
